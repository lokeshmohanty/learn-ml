{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w48UudOSjLnh"
      },
      "source": [
        "## Part II Word2Vec (TA: Nicy Scaria)  (25 Marks)\n",
        "\n",
        "Word2vec is one of the most popular techniques to learn word embeddings. The idea behind word2vec was that the meaning of a word is determined by the context in which it occurs. A word embedding is a learned representation for text where words that have the same meaning have a similar representation.\n",
        "\n",
        "**Word2vec** model has 2 architectures:\n",
        "\n",
        "1. **Continuous bag of word (CBOW):**\n",
        "\n",
        "    CBOW predicts the center word from the surrounding context words.\n",
        "\n",
        "2. **Skip-gram:**\n",
        "\n",
        "    Skip-gram predicts surrounding context words from the center word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pTSKA5fiVQs"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_map_style_dataset\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_vocab_from_iterator\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
          ]
        }
      ],
      "source": [
        "# importing the necessary libraries\n",
        "import torch\n",
        "from functools import partial\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data import to_map_style_dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import WikiText2\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lu8GMxMlZ0f"
      },
      "source": [
        "> **In the following code the add your hyperparameters for the network.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZeXkPW6URMu"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "\n",
        "\n",
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated embeddings\n",
        "\n",
        "\n",
        "SKIPGRAM_N_WORDS = None # the length of the context on each side (k)\n",
        "\n",
        "MIN_WORD_FREQUENCY = None # only words with a minimum word frequency considered\n",
        "MAX_SEQUENCE_LENGTH = None # sentences with length more than this value truncated\n",
        "\n",
        "EMBED_DIMENSION = None # dimension of the word2vec vectors\n",
        "\n",
        "EMBED_MAX_NORM = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxyJ0Q1fT62V"
      },
      "outputs": [],
      "source": [
        "def get_english_tokenizer():\n",
        "    \"\"\"\n",
        "    Documentation:\n",
        "    https://pytorch.org/text/stable/_modules/torchtext/data/utils.html#get_tokenizer\n",
        "    \"\"\"\n",
        "    tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
        "    return tokenizer\n",
        "\n",
        "def get_data_iterator(ds_name, ds_type, data_dir):\n",
        "    \"\"\"\n",
        "    input dataset used:\n",
        "    https://paperswithcode.com/dataset/wikitext-2\n",
        "    This is directly imported from PyTorch.\n",
        "    \"\"\"\n",
        "    data_iter = WikiText2(root=data_dir, split=(ds_type))\n",
        "    data_iter = to_map_style_dataset(data_iter)\n",
        "    return data_iter\n",
        "\n",
        "def build_vocab(data_iter, tokenizer):\n",
        "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
        "\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        map(tokenizer, data_iter),\n",
        "        specials=[\"<unk>\"], #adding special tokens to the vocabulary\n",
        "        min_freq=MIN_WORD_FREQUENCY,\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def collate_skipgram(batch, text_pipeline):\n",
        "    \"\"\"\n",
        "    This function prepares data for training the skipgram model.\n",
        "    It generates pairs of center and context words from the batch of text.\n",
        "\n",
        "    batch: A batch of text data\n",
        "    text_pipeline: A pipeline function that processes text into tokens\n",
        "    (batch_input, batch_output) -> (center word, context words)\n",
        "    \"\"\"\n",
        "    batch_input, batch_output = [], []\n",
        "\n",
        "    # Process each text in the batch\n",
        "    for text in batch:\n",
        "        text_tokens_ids = text_pipeline(text)\n",
        "\n",
        "        # Skip texts shorter than the required window size\n",
        "        if len(text_tokens_ids) < SKIPGRAM_N_WORDS * 2 + 1:\n",
        "            continue\n",
        "\n",
        "        # Truncate texts to a maximum sequence length if specified\n",
        "        if MAX_SEQUENCE_LENGTH:\n",
        "            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n",
        "\n",
        "        # Create training pairs for each word in the text\n",
        "        for idx in range(len(text_tokens_ids) - SKIPGRAM_N_WORDS * 2):\n",
        "            token_id_sequence = text_tokens_ids[idx : (idx + SKIPGRAM_N_WORDS * 2 + 1)]\n",
        "            input_ = token_id_sequence.pop(SKIPGRAM_N_WORDS)\n",
        "            outputs = token_id_sequence\n",
        "\n",
        "            # Add each context word with the center word to the output lists\n",
        "            for output in outputs:\n",
        "                batch_input.append(input_)\n",
        "                batch_output.append(output)\n",
        "\n",
        "    # Convert lists to PyTorch tensors\n",
        "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
        "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
        "\n",
        "    return batch_input, batch_output\n",
        "\n",
        "\n",
        "def get_dataloader_and_vocab(\n",
        "    model_name, ds_name, ds_type, data_dir, batch_size, shuffle, vocab=None\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Prepares a DataLoader and builds a vocabulary for the dataset.\n",
        "    model_name: Name of the model to be used\n",
        "    ds_name: Name of the dataset\n",
        "    ds_type: Type of the dataset (e.g., train, test)\n",
        "    data_dir: Directory where the dataset is stored\n",
        "    batch_size: Size of each batch\n",
        "    vocab: An existing vocabulary, if available\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    data_iter = get_data_iterator(ds_name, ds_type, data_dir)\n",
        "    tokenizer = get_english_tokenizer()\n",
        "\n",
        "    if not vocab:\n",
        "        vocab = build_vocab(data_iter, tokenizer)\n",
        "\n",
        "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "\n",
        "    collate_fn = collate_skipgram\n",
        "\n",
        "    # creates a DataLoader for the dataset\n",
        "\n",
        "    \"\"\"\n",
        "    dataloader documentation\n",
        "    https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(\n",
        "        data_iter,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=partial(collate_fn, text_pipeline=text_pipeline),\n",
        "        )\n",
        "\n",
        "    return dataloader, vocab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Ap0SHCloMj"
      },
      "source": [
        "### Initialize the SkipGram Model\n",
        "\n",
        " **Complete the `initialization` and `forward` function in the following  SkipGram_Model class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NNvSmAgYydH"
      },
      "outputs": [],
      "source": [
        "class SkipGram_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of Skip-Gram model described in paper:\n",
        "    https://arxiv.org/abs/1301.3781\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int):\n",
        "        super(SkipGram_Model, self).__init__()\n",
        "\n",
        "        \"\"\"define the embedding and the linear layer of the network\"\"\"\n",
        "        # this is the initialization for the layers in the skipgram model\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "    def forward(self, inputs_):\n",
        "        \"\"\"define forward function\"\"\"\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # return the output of your final layer to find the minimize the loss\n",
        "\n",
        "        return\n",
        "\n",
        "    def get_word_embedding(self):\n",
        "        \"\"\" return the associated word embeddings for center words \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # return the normalized embeddings as a 2D numpy array (in word2vec models,\n",
        "        # the vector associated with the center word is considered\n",
        "        # word embedding)\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcqxAiTSlwbw"
      },
      "source": [
        "> **The following is the Trainer class for the skip-gram model. Add your code for the `training` and `validation` loops.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wSYVSMlZFwA"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \"\"\"Main class for model training\"\"\"\n",
        "\n",
        "    # NOTE: you are free to add additional inputs/functions\n",
        "    # to the trainer class to make training better\n",
        "    # make sure to define and add it within the input\n",
        "    # and initialization if you are using any additional inputs\n",
        "    # for usage in the function\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        epochs,\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        model_dir,\n",
        "        model_name,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.model_dir = model_dir\n",
        "        self.model_name = model_name\n",
        "        self.loss = {\"train\": [], \"val\": []}\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    # ADD YOUR CODE HERE FOR TRAINING & VALIDATION\n",
        "    # This implementation need not include negative sampling.\n",
        "\n",
        "    # NOTE: you can add additional functions to make training better\n",
        "\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Save final model to directory\n",
        "\n",
        "        \"\"\"\n",
        "        model_path = os.path.join(self.model_dir, \"model.pt\")\n",
        "        torch.save(self.model, model_path)\n",
        "\n",
        "    def save_loss(self):\n",
        "        \"\"\"\n",
        "        Save train/val loss as json file to the directory\n",
        "\n",
        "        \"\"\"\n",
        "        loss_path = os.path.join(self.model_dir, \"loss.json\")\n",
        "        with open(loss_path, \"w\") as fp:\n",
        "            json.dump(self.loss, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BgM-DGTl4qy"
      },
      "source": [
        "> **The following code block defines the various parameters and nomenclature for the training and saving of the skip-gram model. Add numerical values for the `specified hyperparameters`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzoqreghaSgc"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "\n",
        "model_name = 'skipgram'\n",
        "\n",
        "dataset = 'WikiText2'\n",
        "data_dir = './data/'\n",
        "train_batch_size = None\n",
        "val_batch_size = None\n",
        "shuffle = True\n",
        "\n",
        "optimizer = None\n",
        "learning_rate = None\n",
        "epochs = None\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "model_dir = 'SAPname_SRno'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSE1qsvxmEdP"
      },
      "source": [
        "> **The following code block is used to train and save the model. Add the code wherever required**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zMDRVHMZWO6"
      },
      "outputs": [],
      "source": [
        "os.makedirs(model_dir)\n",
        "\n",
        "train_dataloader, vocab = get_dataloader_and_vocab(\n",
        "    model_name=model_name,\n",
        "    ds_name=dataset,\n",
        "    ds_type=\"train\",\n",
        "    data_dir=data_dir,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=shuffle,\n",
        "    vocab=None,\n",
        ")\n",
        "\n",
        "val_dataloader, _ = get_dataloader_and_vocab(\n",
        "    model_name=model_name,\n",
        "    ds_name=dataset,\n",
        "    ds_type=\"valid\",\n",
        "    data_dir=data_dir,\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=shuffle,\n",
        "    vocab=vocab,\n",
        ")\n",
        "\n",
        "vocab_size = len(vocab.get_stoi())\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "model_class = SkipGram_Model\n",
        "model = model_class(vocab_size=vocab_size)\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# You'll have to specify the loss criterion\n",
        "# Your loss function would depend upon whether you\n",
        "# choose to train with negative sampling or not\n",
        "# either of the two are valid choices\n",
        "\n",
        "criterion = None\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# You'll have to specify the optimizer here\n",
        "optimizer = None\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# NOTE: if you are **optionally** using additional options for the trainer\n",
        "# (e.g., a training scheduler), please add them below.\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    epochs=epochs,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    model_dir=model_dir,\n",
        "    model_name=model_name,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(\"Training finished.\")\n",
        "\n",
        "trainer.save_model()\n",
        "trainer.save_loss()\n",
        "vocab_path = os.path.join(model_dir, \"vocab.pt\")\n",
        "torch.save(vocab, vocab_path)\n",
        "print(\"Model artifacts saved to folder:\", model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1PKIac1mMsH"
      },
      "source": [
        "### Let us analyze the performance of the model\n",
        "\n",
        "You'll be evaluated on the quality of the word representations as judged by the word similarity test, and word analogy tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-K93nQt5CTZ"
      },
      "outputs": [],
      "source": [
        "#@title Evaluation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import sys\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80d1lRiD7ms4"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "folder = \"SAPname_SRno\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the saved model\n",
        "model = torch.load(f\"{folder}/model.pt\", map_location=device)\n",
        "vocab = torch.load(f\"{folder}/vocab.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc9AMn5GVUKZ"
      },
      "outputs": [],
      "source": [
        "word_embeddings = model.get_word_embedding()\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "# Save the embeddings to the folder\n",
        "np.save('SAPname_SRno/word_embeddings.npy', word_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pPrbet--qJ"
      },
      "source": [
        "Once the embeddings are trained, we can use a few words to evaluate some desirable properties of word representations.\n",
        "\n",
        "For instance, whether similar words are indeed similar in the high-dimensional space?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7hq6o3z777b"
      },
      "outputs": [],
      "source": [
        "words = ['king', 'queen', 'river', 'water', 'ocean', 'tree', 'plant', 'happy', 'glad', 'mother', 'daughter']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5kAEr9rmYym"
      },
      "source": [
        "> **Write a code to find the similarity of the each word in words with eachother**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCXVzRrh8Dvu"
      },
      "outputs": [],
      "source": [
        "def get_word_similarity(words):\n",
        "  \"\"\"\n",
        "  This function takes the words as input and outputs the word vectors\n",
        "  corresponding to the words obtained from your word2vec model and the\n",
        "  similarity of every word with each other.\n",
        "  word2vec is the embedding matrix corresponding to the given words and\n",
        "  this has to be returned as a numpy array to apply PCA on it whereas,\n",
        "  w2v_similarity[i][j] should contain the similarity of word i with word j\n",
        "\n",
        "  \"\"\"\n",
        "  # ADD YOUR CODE HERE\n",
        "\n",
        "  # you'll have to compute the similarity matrix for the words given above\n",
        "\n",
        "  return word2vec, w2v_similarity\n",
        "\n",
        "word2vec, w2v_similarity = get_word_similarity(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrUjGgstmhx8"
      },
      "source": [
        "Let us visualize this similarity matrix. The similarity of each word with other words in words is displayed as a pandas dataframe and as a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8OVhSUZ8LZT"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(w2v_similarity, columns = words, index = words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AWL0kqAmqsK"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(pd.DataFrame(w2v_similarity, columns = words, index = words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V12MD_EumuA7"
      },
      "source": [
        "The size of the words embedding are reduced to to 2D and displayed as a scatterplot for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF9qSiwNmwzw"
      },
      "outputs": [],
      "source": [
        "# Create a 2-dimensional PCA model of the word vectors using the scikit-learn PCA class\n",
        "# n_components in PCA specifies the no.of dimensions\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit and transform the vectors using PCA model\n",
        "reduced_w2v = pca.fit_transform(word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS9QF8AE8MTG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(reduced_w2v[:,0],reduced_w2v[:,1], s = 12, color = 'red')\n",
        "plt.xlim([-2,2])\n",
        "plt.ylim([-2,2])\n",
        "x, y = reduced_w2v[:,0] , reduced_w2v[:,1]\n",
        "offset = 0.5\n",
        "for i in range(len(x)):\n",
        "    label = words[i]\n",
        "    xi, yi = x[i], y[i]\n",
        "    plt.annotate(label, (xi, yi), xytext=(xi + offset, yi + offset),\n",
        "                 textcoords='offset points', ha='center', va='center')\n",
        "\n",
        "plt.savefig(\"word_similarity.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4w3UUE1m4W_"
      },
      "source": [
        "The 10 most similar word to the given word is calculated in the following code blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvXS4uzd8O7W"
      },
      "outputs": [],
      "source": [
        "def get_top_similar(word: str, topN: int = 10):\n",
        "\n",
        "    \"\"\"\n",
        "    This function calculates the topN words similar to the input word.\n",
        "    If the word is not in vocabulary, then similarity is not calculated.\n",
        "    If the word is in the vocabulary, then the dot product of the embedding\n",
        "    matrix and the word vector is calculated. The topN words are selected.\n",
        "    \"\"\"\n",
        "    word_id = vocab[word]\n",
        "    if word_id == 0:\n",
        "        print(\"Out of vocabulary word\")\n",
        "        return\n",
        "\n",
        "    word_vec = model.get_word_embedding[word_id]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "\n",
        "    dists = np.matmul(model.get_word_embedding, word_vec).flatten()\n",
        "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
        "\n",
        "    topN_dict = {}\n",
        "    for sim_word_id in topN_ids:\n",
        "        sim_word = vocab.lookup_token(sim_word_id)\n",
        "        topN_dict[sim_word] = dists[sim_word_id]\n",
        "\n",
        "    return topN_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atY4cy0J8Tfi"
      },
      "outputs": [],
      "source": [
        "for word, sim in get_top_similar(\"india\").items():\n",
        "   print(\"EVALUATION: most similar words to {}: {:.3f}\".format(word, sim))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-elU-5nAL1"
      },
      "source": [
        "### Analogy Tests\n",
        "\n",
        "Analogy tests include questions of the format a:b::x:?, such tests are used to intrinsically evaluate the quality of word vectors.\n",
        "\n",
        "Here's one example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KrTVR2BnC9N"
      },
      "outputs": [],
      "source": [
        "def get_analogy(word_1, word_2, word_3):\n",
        "\n",
        "  \"\"\"\n",
        "  top 5 most analgous vector calculated correspond to a set similar to\n",
        "  man: woman :: king: ? . This is calculated similar to the above case.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  emb1 = model.get_word_embedding[vocab[word_1]]\n",
        "  emb2 = model.get_word_embedding[vocab[word_2]]\n",
        "  emb3 = model.get_word_embedding[vocab[word_3]]\n",
        "\n",
        "  emb4 = emb1 - emb2 + emb3\n",
        "\n",
        "  # compute dot products between 'emb4' and all word embeddings in the model.\n",
        "  emb4 = np.reshape(emb4, (len(emb4), 1))\n",
        "  dot_product = np.matmul(model.get_word_embedding, emb4).flatten()\n",
        "\n",
        "  top5 = np.argsort(-dot_product)[:5]\n",
        "\n",
        "  return top5, dot_product\n",
        "\n",
        "top5_analogy, dot_product = get_analogy('king', 'man', 'woman')\n",
        "\n",
        "for word_id in top5_analogy:\n",
        "    print(\"{}: {:.3f}\".format(vocab.lookup_token(word_id), dot_product[word_id]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKTVUVPEnGVN"
      },
      "source": [
        "The model performance will be evaluated based on an analogy output for the top 5 words. The following code will used to evaluate the performance of the model on the analogies dataset. We will measure how often the correct answer is a part of the top 5 options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2hbpb_h5KgN",
        "outputId": "51993f16-153e-48e9-b218-6c399b32db41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-22 11:22:20--  https://drive.google.com/uc?export=download&id=1jHx25dECegjtRKBB587nEfHiJesrH0g2\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.101, 74.125.31.102, 74.125.31.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1jHx25dECegjtRKBB587nEfHiJesrH0g2&export=download [following]\n",
            "--2024-01-22 11:22:20--  https://drive.usercontent.google.com/download?id=1jHx25dECegjtRKBB587nEfHiJesrH0g2&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.141.132, 2607:f8b0:400c:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 286075 (279K) [application/octet-stream]\n",
            "Saving to: ‘analogies.txt’\n",
            "\n",
            "analogies.txt       100%[===================>] 279.37K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-22 11:22:20 (89.7 MB/s) - ‘analogies.txt’ saved [286075/286075]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading the file containing a few analogies.\n",
        "# We will change the contents of this file while testing.\n",
        "\n",
        "!wget -O analogies.txt \"https://drive.google.com/uc?export=download&id=1jHx25dECegjtRKBB587nEfHiJesrH0g2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obbMdoMe1Tw7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "def load_and_sample_analogies(file_path, sample_size=5000):\n",
        "    with open(file_path, 'r') as file:\n",
        "        analogies = []\n",
        "        for line in file:\n",
        "            # Split the line into words and ensure it has exactly 4 elements\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 4:\n",
        "                analogies.append(parts)\n",
        "\n",
        "        # Sample analogies\n",
        "        sampled_analogies = random.sample(analogies, min(sample_size, len(analogies)))\n",
        "        return sampled_analogies\n",
        "\n",
        "# Path to your text file\n",
        "# NOTE: analogies used for grading could be slightly different\n",
        "file_path = '/content/analogies.txt'\n",
        "\n",
        "# Load and sample analogies\n",
        "sampled_analogy_dataset = load_and_sample_analogies(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuLvO2cV1W2j"
      },
      "outputs": [],
      "source": [
        "def get_word_id(word, vocab):\n",
        "    \"\"\"check for out of vocabulary items\"\"\"\n",
        "    return vocab[word] if word in vocab else 0\n",
        "\n",
        "def analogy_score(analogy_dataset):\n",
        "    \"\"\"\n",
        "    The top5 analogous words calculated for each set of words for your\n",
        "    implementation of word2vec and compared with an existing dataset to\n",
        "    calculate if the expected word is in the first 5 predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for a, b, c, d in analogy_dataset:\n",
        "        # Convert words to lowercase\n",
        "        a, b, c, d = a.lower(), b.lower(), c.lower(), d.lower()\n",
        "\n",
        "        # Check if any word is out of vocabulary\n",
        "        if 0 in [get_word_id(word, vocab) for word in [a, b, c, d]]:\n",
        "            continue\n",
        "\n",
        "        #finding the first five words that are analogous to the given set\n",
        "        top5_analogy, dot_product = get_analogy(a, b, c)\n",
        "\n",
        "        predicted_words = []\n",
        "\n",
        "        for word_id in top5_analogy:\n",
        "            word = vocab.lookup_token(word_id)\n",
        "            predicted_words.append(word)\n",
        "\n",
        "        if d in predicted_words:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    precision_at_5 = correct / total if total > 0 else 0\n",
        "    return precision_at_5\n",
        "\n",
        "precision_at_5 = analogy_score(sampled_analogy_dataset)\n",
        "print(\"EVALUATION: Precision at 5 for the analogy test is\", precision_at_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwjiemeOnKvj"
      },
      "source": [
        "#### Google's word2vec for comparison\n",
        "\n",
        "In the following code blocks, the pretained word2vec developed by Google is used to analyze the quality of the embedding. The word2vec model can be downloaded from [here](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KhiakvJ3wwe",
        "outputId": "b833be2d-b1b8-4417-c575-454b40191526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-22 11:52:16--  https://drive.google.com/uc?export=download&id=12Oicgl5scdJLR7t8jbzKpW6o8QkYOylg\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.100, 74.125.31.102, 74.125.31.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=12Oicgl5scdJLR7t8jbzKpW6o8QkYOylg&export=download [following]\n",
            "--2024-01-22 11:52:16--  https://drive.usercontent.google.com/download?id=12Oicgl5scdJLR7t8jbzKpW6o8QkYOylg&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.141.132, 2607:f8b0:400c:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2446 (2.4K) [text/html]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin’\n",
            "\n",
            "\r          GoogleNew   0%[                    ]       0  --.-KB/s               \rGoogleNews-vectors- 100%[===================>]   2.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-22 11:52:16 (17.9 MB/s) - ‘GoogleNews-vectors-negative300.bin’ saved [2446/2446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O GoogleNews-vectors-negative300.bin \"https://drive.google.com/uc?export=download&id=12Oicgl5scdJLR7t8jbzKpW6o8QkYOylg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "c8bca5cf80de4948ad86ed9b08469b75",
            "3d0983ae13a34bd9a1635309867cb9cd",
            "c8fbb3415ad941d0b138bc5743f77ac3",
            "b2eadb5f487e45f983771b9c4601ee78",
            "89b7ea42b66e4ea5952f13cea491b9bf",
            "c3053e733101432985d8a9e480d2a29b",
            "de9d707864cd47c28ce47383890c023b",
            "499b50c69b2a43e18aacf4214ecd5b7c",
            "27d2150a6c6a4291bcfee282f491df88",
            "b81d3faa449543a183922d2eafefe47e",
            "93633618c22a48b88dda45059886daf4"
          ]
        },
        "id": "KNMjvv4K2xd0",
        "outputId": "3b03f980-b74e-4a11-cd70-7d62f60007e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8bca5cf80de4948ad86ed9b08469b75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/3.39G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded to /content/GoogleNews-vectors-negative300.bin\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "import requests\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "def download_from_drive(drive_link, target_path):\n",
        "    response = requests.get(drive_link, stream=True)\n",
        "    response.raise_for_status()\n",
        "    if 'html' in response.headers['Content-Type']:\n",
        "        response = requests.get(drive_link)\n",
        "        response.raise_for_status()\n",
        "        page = bs4.BeautifulSoup(response.text, features=\"lxml\")\n",
        "        if form := page.find('form', id='download-form'):\n",
        "            id   = form.select_one(\"input[name='id']\")['value']\n",
        "            uuid = form.select_one(\"input[name='uuid']\")['value']\n",
        "            data = { 'confirm': 't', 'export': 'download', 'id': id, 'uuid': uuid }\n",
        "            response = requests.get(page.find('form')['action'], params=data, stream=True)\n",
        "            response.raise_for_status()\n",
        "    with open(target_path, 'wb+') as file:\n",
        "        with tqdm.tqdm(\n",
        "            total=int(response.headers['Content-Length']),\n",
        "            unit='B', unit_scale=True, unit_divisor=1024\n",
        "        ) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=4096):\n",
        "                file.write(chunk)\n",
        "                pbar.update(len(chunk))\n",
        "    print(\"Downloaded to\", target_path)\n",
        "\n",
        "drive_link = \"https://drive.google.com/uc?export=download&id=12Oicgl5scdJLR7t8jbzKpW6o8QkYOylg\"\n",
        "target_path = \"/content/GoogleNews-vectors-negative300.bin\"\n",
        "\n",
        "download_from_drive(drive_link, target_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzoahZOUnQIO"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "\n",
        "# Load Google news 300 vectors file\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, limit=500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep71XY238WpV"
      },
      "outputs": [],
      "source": [
        "# List of words to plot the embeddings\n",
        "words = ['king', 'queen', 'river', 'water', 'ocean', 'tree', 'plant', 'happy', 'glad', 'mother', 'daughter']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUtqxPrnWV9"
      },
      "source": [
        "> **Write a code to find the similarity of the each word in words with eachother using original word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QLcfJvvnYl9"
      },
      "outputs": [],
      "source": [
        "def get_word_similarity(words):\n",
        "  \"\"\"\n",
        "  This function takes the words as input and outputs the word vectors\n",
        "  corresponding to the words using Google's word2vec and the similarity of\n",
        "  every word with eachother. word2vec is the embedding matrix for the words\n",
        "  given above w2v_similarity[i][j] should contain the similarity of word i with j\n",
        "\n",
        "  \"\"\"\n",
        "  # ADD YOUR CODE HERE\n",
        "\n",
        "  # you'll have to compute the similarity matrix for the words given above\n",
        "\n",
        "  return word2vec, w2v_similarity\n",
        "\n",
        "word2vec, w2v_similarity = get_word_similarity(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLQn4B_snbfg"
      },
      "source": [
        "The similarity of each word with other words in words is displayed as a pandas dataframe and as a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3-NqzVunhg1"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(w2v_similarity, columns = words, index = words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koErrEInnjcd"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(pd.DataFrame(w2v_similarity, columns = words, index = words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptKTusGJnpLy"
      },
      "source": [
        "The size of the words embedding are reduced to to 2D and displayed as a scatterplot for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADEMWok8nrX0"
      },
      "outputs": [],
      "source": [
        "#PCA on word2vec embedding\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "reduced_w2v = pca.fit_transform(word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la2osFTxntIc"
      },
      "outputs": [],
      "source": [
        "#plotting reduced order embeddings in a 2-D space\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(reduced_w2v[:,0],reduced_w2v[:,1], s = 12, color = 'red')\n",
        "plt.xlim([-2.5,2.5])\n",
        "plt.ylim([-2.5,2.5])\n",
        "x, y = reduced_w2v[:,0] , reduced_w2v[:,1]\n",
        "for i in range(len(x)):\n",
        "    plt.annotate(words[i],xy=(x[i], y[i]),xytext=(x[i]+0.05,y[i]+0.05))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Whg_kv2QnvXW"
      },
      "outputs": [],
      "source": [
        "model.most_similar('india')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIx8JEMynzK5"
      },
      "source": [
        "Analogy test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N41c0AJKnzou"
      },
      "outputs": [],
      "source": [
        "def analogy(x1, x2, y1): #defining analogy function\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1], topn = 5)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbEfS_7An3RF"
      },
      "outputs": [],
      "source": [
        "analogy('man', 'king', 'woman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbqo3EhNy952"
      },
      "outputs": [],
      "source": [
        "def analogy_score(analogy_dataset):\n",
        "\n",
        "    \"\"\"\n",
        "    The top5 analogous words calculated for each set of words for Google's\n",
        "    word2vec and compared with an existing dataset to calculate if the word\n",
        "    is in the first 5 predictions.\n",
        "\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for a, b, c, d in analogy_dataset:\n",
        "        # Convert words to lowercase\n",
        "        a, b, c, d = a.lower(), b.lower(), c.lower(), d.lower()\n",
        "\n",
        "        words_scores = analogy(a,b,c)\n",
        "\n",
        "        predicted_words = [item[0] for item in words_scores]\n",
        "\n",
        "        if d in predicted_words:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    precision_at_5 = correct / total if total > 0 else 0\n",
        "    return precision_at_5\n",
        "\n",
        "precision_at_5_Google = analogy_score(sampled_analogy_dataset)\n",
        "print(\"EVALUATION: Precision at 5 for the analogy test with Google skip-gram model is\", precision_at_5_Google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acp_DOcZn5j2"
      },
      "source": [
        "### Submission Instructions\n",
        "\n",
        "Mentioned at the top of the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27d2150a6c6a4291bcfee282f491df88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d0983ae13a34bd9a1635309867cb9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3053e733101432985d8a9e480d2a29b",
            "placeholder": "​",
            "style": "IPY_MODEL_de9d707864cd47c28ce47383890c023b",
            "value": "100%"
          }
        },
        "499b50c69b2a43e18aacf4214ecd5b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b7ea42b66e4ea5952f13cea491b9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93633618c22a48b88dda45059886daf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2eadb5f487e45f983771b9c4601ee78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81d3faa449543a183922d2eafefe47e",
            "placeholder": "​",
            "style": "IPY_MODEL_93633618c22a48b88dda45059886daf4",
            "value": " 3.39G/3.39G [01:08&lt;00:00, 56.6MB/s]"
          }
        },
        "b81d3faa449543a183922d2eafefe47e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3053e733101432985d8a9e480d2a29b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bca5cf80de4948ad86ed9b08469b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d0983ae13a34bd9a1635309867cb9cd",
              "IPY_MODEL_c8fbb3415ad941d0b138bc5743f77ac3",
              "IPY_MODEL_b2eadb5f487e45f983771b9c4601ee78"
            ],
            "layout": "IPY_MODEL_89b7ea42b66e4ea5952f13cea491b9bf"
          }
        },
        "c8fbb3415ad941d0b138bc5743f77ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_499b50c69b2a43e18aacf4214ecd5b7c",
            "max": 3644258522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27d2150a6c6a4291bcfee282f491df88",
            "value": 3644258522
          }
        },
        "de9d707864cd47c28ce47383890c023b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
