{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feef5a99-a4df-4b23-8977-38a2a8820810",
   "metadata": {},
   "source": [
    "# RL Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "917d284c-f7c0-4dd2-b314-a3dd6072a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "    \n",
    "class cartpole:\n",
    "    qtable = []\n",
    "    n_actions = []\n",
    "    PRNGKey = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "        self.n_actions = np.zeros(env.action_space.n)\n",
    "        self.qtable = np.zeros((4, 4, 2)) + 0.5\n",
    "        # self.PRNGKey = random.PRNGKey(0)\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "    def get_state(self, obs):\n",
    "        state_pos = [self.env.observation_space.low[0]/2, self.env.observation_space.high[0]/2]\n",
    "        state_ang = [self.env.observation_space.low[2]/2, self.env.observation_space.high[2]/2]\n",
    "        pos, ang = [int((n_pos) * (obs[0] - state_pos[0]) / (state_pos[1] - state_pos[0])),\n",
    "                    int((n_ang) * (obs[2] - state_ang[0]) / (state_ang[1] - state_ang[0]))]\n",
    "        return [0 if pos < 0 else 3 if pos > 3 else pos, 0 if ang < 0 else 3 if ang > 3 else ang]\n",
    "        \n",
    "    def choose_action(self, observation, eps=0.3):\n",
    "        state = self.get_state(observation)\n",
    "        if self.get_random() < eps:\n",
    "            return env.action_space.sample()\n",
    "        return int(np.argmax(self.qtable[state[0]][state[1]]))\n",
    "\n",
    "    def get_random(self):\n",
    "        # old_key, new_key = random.split(self.PRNGKey)\n",
    "        # self.PRNGKey = new_key\n",
    "        # return random.uniform(old_key)\n",
    "        return self.rng.random()\n",
    "        \n",
    "        \n",
    "class episodic(cartpole):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def train(self, episodes=1000):\n",
    "        for _ in tqdm(range(episodes)):\n",
    "            state_action = []\n",
    "            rewards = 0\n",
    "            observation, info = env.reset()\n",
    "            terminated, truncated = 0, 0\n",
    "            while(not (terminated or truncated)):\n",
    "                action = self.choose_action(observation)\n",
    "                state_action.append((self.get_state(observation), action))\n",
    "                observation, reward, terminated, truncated, info = env.step(action)\n",
    "                rewards += reward\n",
    "            self.update_qtable(state_action, reward)\n",
    "        env.close()\n",
    "\n",
    "    def update_qtable(self, state_action, reward):\n",
    "        for s, a in state_action:\n",
    "            self.n_actions += 1\n",
    "            self.qtable[*s, a] += (reward - self.qtable[*s, a]) / self.n_actions[a]\n",
    "            # self.n_actions = self.n_actions.at[a].set(self.n_actions[a] + 1)\n",
    "            # self.qtable = self.qtable.at[*s, a].set(self.qtable[*s, a] + (reward - self.qtable[*s, a]) / self.n_actions[a])\n",
    "\n",
    "class continuous(cartpole):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, max_iter=100000, gamma=0.9):\n",
    "        observation, info = env.reset()\n",
    "        for _ in tqdm(range(max_iter)):\n",
    "            action = self.choose_action(observation)\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            self.update_qtable(observation, action, -1 if terminated else reward, gamma)\n",
    "            if terminated or truncated:\n",
    "                observation, info = env.reset()\n",
    "\n",
    "    def update_qtable(self, observation, action, reward, gamma):\n",
    "        state = self.get_state(observation)\n",
    "        s, a = state, action\n",
    "        self.n_actions += 1\n",
    "        self.qtable[*s, a] += gamma * (reward - self.qtable[*s, a]) / self.n_actions[a]\n",
    "        # self.n_actions = self.n_actions.at[a].set(self.n_actions[a] + 1)\n",
    "        # self.qtable = self.qtable.at[*s, a].set(self.qtable[*s, a] + gamma * (reward - self.qtable[*s, a]) / self.n_actions[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "837c83c2-7ad6-4e0d-b890-4a0d2afb0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodic_pole = episodic()\n",
    "continuous_pole = continuous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfe753-8611-4611-bd9a-c34b3ddef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodic_pole.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "504db7f9-dd74-4bb8-a0a6-bd2fd87a76dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 100000/100000 [36:08<00:00, 46.11it/s]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "continuous_pole.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "104b3bc7-023e-4f54-b7b0-4abd6395285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = episodic_pole.env.reset()\n",
    "s = episodic_pole.get_state(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8305b39c-9424-49e2-aeb7-772b9266d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable1 = episodic_pole.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93a9902c-c4a4-4aa1-8c5e-f0b551aa9fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodic_pole.qtable[*s, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6676797-ce4d-4235-9ad7-0dd55f234261",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable2 = continuous_pole.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4cac8649-f9b6-4d90-8bcd-330980fce9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]]\n",
      "\n",
      " [[0.5        0.5       ]\n",
      "  [0.82676477 0.58989917]\n",
      "  [0.97249807 0.6827857 ]\n",
      "  [0.90831967 0.59039693]]\n",
      "\n",
      " [[0.50056495 0.50127997]\n",
      "  [1.         0.53738949]\n",
      "  [0.76266717 0.53865689]\n",
      "  [0.50133477 0.5       ]]\n",
      "\n",
      " [[0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]]]\n",
      "[[[0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]\n",
      "  [0.5        0.5       ]]\n",
      "\n",
      " [[0.5052258  0.50103514]\n",
      "  [0.98918956 0.5394394 ]\n",
      "  [0.97538865 0.71112578]\n",
      "  [0.52468836 0.52467087]]\n",
      "\n",
      " [[0.51463924 0.5016634 ]\n",
      "  [0.76027548 0.56012859]\n",
      "  [0.80643053 0.56768878]\n",
      "  [0.50852782 0.51707979]]\n",
      "\n",
      " [[0.50063688 0.50005795]\n",
      "  [0.5004586  0.50001064]\n",
      "  [0.50021607 0.50001063]\n",
      "  [0.4999857  0.4998891 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(qtable1)\n",
    "print(qtable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93850466-756b-48da-9cb3-ab257e7de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()\n",
    "for _ in range(1000):\n",
    "    # action = episodic_pole.choose_action(observation)\n",
    "    action = continuous_pole.choose_action(observation)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add0e3a-d3a6-4616-ab9e-ddd8e1093f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
